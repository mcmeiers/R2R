## Basic Example
This example demonstrates setting up a local server using the R2R framework to host a RAG pipeline, which includes ingestion, embedding, and generation processes. Following the server setup, you'll interact with it using a client to ingest PDF data, perform searches, and generate responses, showcasing the framework's capabilities for advanced document processing and retrieval-augmented generation.

## Step 0: Dependencies

```bash
# use the `'r2r[all]'` to download all required deps
pip install 'r2r[eval]'

export OPENAI_API_KEY="replace with your openai key"
export LOCAL_DB_PATH=local.sqlite
```

## Step 1: Launch the Basic Application Server

To launch the basic application server, run the following command:

```bash
python -m r2r.examples.servers.config_pipeline
```

This command starts the backend server with the Q&A RAG pipeline, which includes the ingestion, embedding, and RAG pipelines served via FastAPI.

## Step 2: Ingest the Demo PDF Data Using a Client

To ingest the demo PDF data, use the following command:

```bash
python -m r2r.examples.clients.run_qna_client ingest meditations
```

This command uploads the `meditations.pdf` file located in the `examples/data` directory and processes it using the ingestion pipeline. The output should be similar to:

```
Upload response = {'message': "File 'meditations.pdf' processed and saved at '/path/to/uploads/meditations.pdf'"}
```

## Step 3: Perform a Search Using a Client

To perform a search on the ingested PDF data, run the following command:

```bash
python -m r2r.examples.clients.run_qna_client search "what is the meditations about?"
```

This command searches the ingested PDF data for information related to the query "what is the meditations about?". The output should include relevant text snippets from the PDF, such as:

```
Result 1: Title: Meditations - Marcus Aurelius
Middle things, Book 7,XXV. TheStoics divided allthings into
virtue, vice ...
```

## Step 4: Perform a Completion with RAG

To generate a completion using the RAG (Retrieval-Augmented Generation) pipeline, run the following command:

```bash
python -m r2r.examples.clients.run_qna_client rag_completion "what is the meditations about?"
```

This command utilizes the RAG pipeline to generate a comprehensive answer to the query "what is the meditations about?". The output should include a detailed response based on the ingested PDF data, similar to:

```
{
  ...
  'message': {'content': '"Meditations" by Marcus Aurelius is a series of personal writings by the Roman Emperor, reflecting his thoughts on Stoic philosophy. The text delves into the nature of the human mind, ethics, and the universe, advocating for a life of virtue, rationality, and self-restraint. Aurelius discusses the importance of understanding one\'s place in the cosmos and the need to live in harmony with nature and society. He emphasizes the significance of inner peace, the control of one\'s desires and emotions, and the pursuit of goodness as the highest goal. Through his meditations, Aurelius seeks to provide guidance on leading a meaningful life, focusing on personal improvement and the development of a moral character in accordance with Stoic principles.'}
  ...
}
```

The RAG pipeline retrieves relevant information from the ingested PDF data and generates a coherent and informative response to the given query.

## Step 5: Perform Streaming Completion with RAG
To generate a streaming completion, run the following command:
```bash
python -m r2r.examples.clients.run_qna_client rag_completion_streaming "what is the meditations about?"
```
You should be able to see the response getting streamed to your console as it's getting generated.


## Step 6: Get Server logs
To get server logs using the client, run the following command:
```
python -m r2r.examples.clients.run_qna_client get_logs
```

Or, if you just want the summary of the logs, run:
```
python -m r2r.examples.clients.run_qna_client get_logs_summary
```

## Optional Step 7: Connect to web application
Navigate to the [demo application](https://github.com/SciPhi-AI/R2R-App-Demo) and follow the listed instructions.


## Optional Step 8: Configure the Application
You can refer to [configure your pipeline](configure-your-pipeline.mdx) to learn more.

## Optional Step 9: Customize the Application
You can refer to [customize your pipeline](customize-your-pipeline.mdx) to learn more.